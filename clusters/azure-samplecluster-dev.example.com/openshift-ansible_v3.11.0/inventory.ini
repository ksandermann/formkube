[OSEv3:children]
masters
nodes
etcd
#lb commented out as we use the provisioned Azure loadbalancer

# Vars for all OSEv3 hosts
[OSEv3:vars]
#################################################### ANSIBLE ###########################################################
ansible_ssh_user=clusteradmin
ansible_ssh_private_key_file="~/.ssh/samplecluster-dev.example.com_bastions"
ansible_become=true
ansible_ssh_common_args="-o ProxyCommand='ssh -W %h:%p -q clusteradmin@bastion1.samplecluster-dev.example.com'"


#################################################### GENERIC ###########################################################
openshift_deployment_type=origin
openshift_clock_enabled=true
openshift_rolling_restart_mode=system
# Native high availability cluster method with optional load balancer.
# If no lb group is defined installer assumes that a load balancer has
# been preconfigured. For installation the value of
# openshift_master_cluster_hostname must resolve to the load balancer
# or to one or all of the masters defined in the inventory if no load
# balancer is present.
openshift_master_cluster_method=native
openshift_master_cluster_hostname=os.samplecluster-dev.example.com
openshift_master_cluster_public_hostname=os.samplecluster-dev.example.com
openshift_master_api_port=6443
openshift_master_console_port=6443

use_openshift_sdn=True

#################################################### IAM ###############################################################
# htpasswd auth
openshift_master_identity_providers=[{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider'}]
openshift_master_htpasswd_users={'c.admin': '$apr1$be09/5V4$/SpzeDGoTBPNxN6DJWgPS1'}


#################################################### DNS ###############################################################
openshift_master_default_subdomain=apps.samplecluster-dev.example.com

#################################################### NETWORKING ########################################################
#pods
osm_cluster_network_cidr=10.128.0.0/14

#services
openshift_portal_net=172.30.0.0/16

# proxy configuration
openshift_no_proxy=".example.com,.samplecluster-dev.example.com"

# firewall
os_firewall_use_firewalld=True

#################################################### STORAGE ###########################################################
openshift_master_dynamic_provisioning_enabled=True

#################################################### CERTS #############################################################
openshift_hosted_registry_cert_expire_days=730
openshift_ca_cert_expire_days=1825
openshift_node_cert_expire_days=730
openshift_master_cert_expire_days=730
etcd_ca_default_days=1825
# certs
# -> The absolute path on the control node to the CA file to use for the browser facing ops Kibana certs.

#################################################### REGISTRY ##########################################################
openshift_hosted_registry_routehost=registry.samplecluster-dev.example.com
openshift_hosted_registry_routetermination=reencrypt

#################################################### METRICS ###########################################################
# generic
openshift_metrics_install_metrics=true
openshift_metrics_start_cluster=true
openshift_metrics_startup_timeout=360
# keep 1 week of metrics
openshift_metrics_duration=7
#The frequency that metrics are gathered. Defined as a number and time identifier: seconds (s), minutes (m), hours (h).
openshift_metrics_resolution="10s"

# cassandra
openshift_metrics_cassandra_storage_type=dynamic
#-> no need to specify as dynamic-storage will always create a default sc
;#openshift_metrics_cassandra_pvc_storage_class_name=vsphere-standard
openshift_metrics_cassandra_pvc_size=5Gi
openshift_metrics_cassandra_replicas=1
openshift_metrics_cassandra_nodeselector={"node-role.kubernetes.io/infra":"true"}
openshift_metrics_cassandra_limits_memory="2Gi"
openshift_metrics_cassandra_limits_cpu="2"
openshift_metrics_cassandra_requests_memory="1Gi"
openshift_metrics_cassandra_requests_cpu="500m"

# hawkular
openshift_metrics_hawkular_hostname=hawkular-metrics.samplecluster-dev.example.com
openshift_metrics_hawkular_replicas=1
openshift_metrics_hawkular_nodeselector={"node-role.kubernetes.io/infra":"true"}
openshift_metrics_hawkular_limits_memory="2Gi"
openshift_metrics_hawkular_limits_cpu="2"
openshift_metrics_hawkular_requests_memory="512Mi"
openshift_metrics_hawkular_requests_cpu="500m"

# heapster
openshift_metrics_heapster_standalone=false
openshift_metrics_heapster_nodeselector={"node-role.kubernetes.io/infra":"true"}
openshift_metrics_heapster_limits_memory="512Mi"
openshift_metrics_heapster_limits_cpu="500m"
openshift_metrics_heapster_requests_memory="256Mi"
openshift_metrics_heapster_requests_cpu="100m"

#################################################### MONITORING ########################################################
# operator
openshift_cluster_monitoring_operator_install=true
openshift_cluster_monitoring_operator_node_selector={"node-role.kubernetes.io/infra":"true"}

# prometheus
openshift_cluster_monitoring_operator_prometheus_storage_enabled=true
openshift_cluster_monitoring_operator_prometheus_storage_capacity=5Gi
#-> no need to specify as dynamic-storage will always create a default sc
#openshift_cluster_monitoring_operator_prometheus_storage_class_name=vsphere-standard

# alertmanager
#can't be configured now as telegram is not supported and mail needs smtp
#https://docs.okd.io/latest/install_config/prometheus_cluster_monitoring.html#configuring-alertmanager
#openshift_cluster_monitoring_operator_alertmanager_config=""
openshift_cluster_monitoring_operator_alertmanager_storage_enabled=true
openshift_cluster_monitoring_operator_alertmanager_storage_capacity=2Gi
#-> no need to specify as dynamic-storage will always create a default sc
#openshift_cluster_monitoring_operator_alertmanager_storage_class_name=vsphere-standard

#not documented
openshift_prometheus_cpu_limit="4"
openshift_prometheus_memory_limit="4Gi"
openshift_prometheus_cpu_requests="500m"
openshift_prometheus_memory_requests="512Mi"
openshift_prometheus_alertmanager_cpu_limit="250m"
openshift_prometheus_alertmanager_memory_limit="256Mi"
openshift_prometheus_alertmanager_cpu_requests="50m"
openshift_prometheus_alertmanager_memory_requests="128Mi"
openshift_prometheus_alertbuffer_cpu_limit="250m"
openshift_prometheus_alertbuffer_memory_limit="256Mi"
openshift_prometheus_alertbuffer_cpu_requests="50m"
openshift_prometheus_alertbuffer_memory_requests="128Mi"
openshift_prometheus_oauth_proxy_cpu_limit="500m"
openshift_prometheus_oauth_proxy_memory_limit="512Mi"
openshift_prometheus_oauth_proxy_cpu_requests="50m"
openshift_prometheus_oauth_proxy_memory_requests="256Mi"
openshift_prometheus_node_exporter_cpu_limit="200m"
openshift_prometheus_node_exporter_memory_limit="50Mi"
openshift_prometheus_node_exporter_cpu_requests="100m"
openshift_prometheus_node_exporter_memory_requests="30Mi"

# grafana
#not documented
# TRYOUT
openshift_grafana_storage_type=pvc
openshift_grafana_pvc_size="5Gi"
openshift_grafana_namespace=openshift-monitoring
openshift_grafana_hostname=grafana.ops.samplecluster-dev.example.com
openshift_grafana_cpu_limit="1"
openshift_grafana_memory_limit="2Gi"
openshift_grafana_cpu_requests="500m"
openshift_grafana_memory_requests="512Mi"
openshift_grafana_oauth_proxy_cpu_limit="250m"
openshift_grafana_oauth_proxy_memory_limit="256Mi"
openshift_grafana_oauth_proxy_cpu_requests="100m"
openshift_grafana_oauth_proxy_memory_requests="128Mi"

#################################################### LOGGING ##########################################################
# general
openshift_logging_install_logging=true
openshift_logging_use_ops=true
openshift_logging_master_url=https://kubernetes.default.svc.cluster.local
openshift_logging_purge_logging=false
openshift_master_logging_public_url=logs.samplecluster-dev.example.com

# eventrouter
openshift_logging_install_eventrouter=true
openshift_logging_eventrouter_sink=stdout
openshift_logging_eventrouter_nodeselector={"node-role.kubernetes.io/infra":"true"}
openshift_logging_eventrouter_replicas=1
openshift_logging_eventrouter_cpu_limit="100m"
openshift_logging_eventrouter_memory_limit="128Mi"
openshift_logging_eventrouter_namespace=openshift-logging

# kibana
openshift_logging_kibana_hostname=kibana.samplecluster-dev.example.com
openshift_logging_kibana_nodeselector={"node-role.kubernetes.io/infra":"true"}
openshift_logging_kibana_replica_count=1
openshift_logging_kibana_cpu_limit="1"
openshift_logging_kibana_memory_limit="736Mi"
openshift_logging_kibana_proxy_cpu_limit="500m"
openshift_logging_kibana_proxy_memory_limit="256Mi"

# kibana-ops
openshift_logging_kibana_ops_hostname=kibana.ops.samplecluster-dev.example.com
openshift_logging_kibana_ops_nodeselector={"node-role.kubernetes.io/infra":"true"}
openshift_logging_kibana_ops_replica_count=1
openshift_logging_kibana_ops_cpu_limit="1"
openshift_logging_kibana_ops_memory_limit="736Mi"
openshift_logging_kibana_ops_proxy_cpu_limit="500m"
openshift_logging_kibana_ops_proxy_memory_limit="256Mi"

# curator

openshift_logging_curator_cpu_limit="500m"
openshift_logging_curator_memory_limit="256Mi"

# curator-ops
openshift_logging_curator_ops_cpu_limit="500m"
openshift_logging_curator_ops_memory_limit="256Mi"

#keep 2 months of logs
#openshift_logging_curator_default_days=60

#-> breaks the deployment due to a bug in openshift-ansible
#openshift_logging_curator_nodeselector={"node-role.kubernetes.io/infra":"true"}
#openshift_logging_curator_ops_nodeselector={"node-role.kubernetes.io/infra":"true"}

# elastic
openshift_logging_es_allow_external=true
openshift_logging_es_hostname=elastic.samplecluster-dev.example.com
openshift_logging_es_cluster_size=1
openshift_logging_es_number_of_replicas=0
openshift_logging_es_number_of_shards=1
openshift_logging_es_pvc_dynamic=true
#-> no need to specify as dynamic-storage will always create a default sc
#openshift_logging_es_pvc_storage_class_name=vsphere-standard
openshift_logging_es_pvc_size=5G
openshift_logging_elasticsearch_storage_type=pvc
openshift_logging_es_nodeselector={"node-role.kubernetes.io/infra":"true"}
openshift_logging_es_cpu_limit="2"
openshift_logging_es_memory_limit="1Gi"
openshift_logging_es_cpu_request="1"

# elastic-ops
openshift_logging_es_ops_allow_external=true
openshift_logging_es_ops_hostname=elastic.ops.samplecluster-dev.example.com
openshift_logging_es_ops_cluster_size=1
openshift_logging_es_ops_pvc_dynamic=true
openshift_logging_es_ops_pvc_size=5G
openshift_logging_es_ops_nodeselector={"node-role.kubernetes.io/infra":"true"}
openshift_logging_elasticsearch_kibana_index_mode=shared_ops
openshift_logging_elasticsearch_poll_timeout_minutes=90
openshift_logging_es_ops_cpu_limit="2"
openshift_logging_es_ops_memory_limit="1Gi"
openshift_logging_es_ops_cpu_request="1"


# fluentd
openshift_logging_fluentd_audit_container_engine=true
openshift_logging_fluentd_cpu_limit="500m"

#does not do what the docs say:
#openshift_logging_es_host=logging-es.openshift-logging.svc.cluster.local
#openshift_logging_es_port=9200
#openshift_logging_es_ops_host=logging-es-ops.openshift-logging.svc.cluster.local
#openshift_logging_es_ops_port=9200
# wrong documentation - role openshift_logging_fluentd uses the following variables to templates daemonset:
openshift_logging_fluentd_app_host=logging-es.openshift-logging.svc.cluster.local
openshift_logging_fluentd_app_port=9200
openshift_logging_fluentd_ops_host=logging-es-ops.openshift-logging.svc.cluster.local
openshift_logging_fluentd_ops_port=9200


#################################################### SERVICE CATALOG ###################################################
openshift_enable_service_catalog=true

template_service_broker_install=true

#https://docs.okd.io/3.11/architecture/service_catalog/ansible_service_broker.html#arch-ansible-service-broker
#https://docs.okd.io/3.11/apb_devel/index.html#apb-devel-intro-design
ansible_service_broker_install=true

#################################################### CONSOLES ##########################################################
# web console
openshift_web_console_install=true

# cluster console
openshift_console_install=true
openshift_console_hostname=cluster.samplecluster-dev.example.com

#################################################### CLOUD PROVIDER ####################################################

openshift_cloudprovider_kind=azure
#openshift_cloudprovider_azure_client_id= -> set in deploy script call
#openshift_cloudprovider_azure_client_secret= -> set in deploy script call
#openshift_cloudprovider_azure_tenant_id= -> set in deploy script call
#openshift_cloudprovider_azure_subscription_id= -> set in deploy script call
openshift_cloudprovider_azure_resource_group=samplecluster-dev.example.com
openshift_cloudprovider_azure_location=northeurope

#################################################### HOST GROUPS #######################################################

# masters
[masters]
10.0.1.10 openshift_public_hostname=master1.samplecluster-dev.example.com openshift_node_group_name='node-config-master'

# etcd
[etcd]
10.0.1.10 openshift_public_hostname=master1.samplecluster-dev.example.com openshift_node_group_name='node-config-master'

# nodes
[nodes]
10.0.1.100 openshift_public_hostname=computenode1.samplecluster-dev.example.com openshift_node_group_name='node-config-compute' openshift_schedulable=true
10.0.1.200 openshift_public_hostname=infranode1.samplecluster-dev.example.com openshift_node_group_name='node-config-infra'


